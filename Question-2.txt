Question:
=========
1. Write a small program (shellscript, python, perl, ruby are all permissible) to uncover the top 10 bandwidth consumers as logged by a standard nginx/Apache 2.2.x webserver log.

Solution:
=========
So the most bandwidth consumers will be the numbers of users who had logged into the server multiple time; so if we can get the top 10 IP address which is recorded in the logs should be the workaround.

Considering the log file if that we are checking is access.log than 

======
#!/usr/local/bin/bash

#### Doing the awk on the file to find the IP address ####
#### Sort -nr   - to sort the IPadress ####
#### uniq -c    - will give the counts of unqiue entries 
#### Sort -r    - Sort in the Decending order 
#### head -n10  - Gives the top 10 entries

   awk '{print $1}' access.log | sort -nr | uniq -c | sort -r | head -n10
======

Example Output :

     27 68.12.37.118
     23 68.14.23.63
     13 10.82.21.20
     10 68.142.27.112
      8 68.12.27.12

Question :
===========
2. Modify your application to only inspect the last 10,000 lines of the log

Solution :
=======
I believe the requirement here is to print the 10,000lines in the log which can be done using :
   
     *****************
         see -n ‘1,10000p’ access.log
     *****************

For example :
    ********************************************************
          $ sed -n '1, 10p' access_log-20161111 | cat -n
     1	13.82.217.20 - - [10/Nov/2016:09:55:27 +0530] "GET / HTTP/1.0" 200 8 "-" "Lynx/2.8.6rel.5 libwww-FM/2.14 SSL-MM/1.4.1 OpenSSL/1.0.0-fips"
     2	10.182.217.20 - - [10/Nov/2016:09:55:38 +0530] "GET / HTTP/1.0" 200 8 "-" "Wget/1.12 (linux-gnu)"
     3	101.82.217.20 - - [10/Nov/2016:09:57:23 +0530] "GET / HTTP/1.0" 200 8 "-" "Wget/1.12 (linux-gnu)"
     4	38.14.237.118 - - [10/Nov/2016:18:17:46 +0530] "GET / HTTP/1.0" 200 8 "-" "-"
     5	58.42.7.118 - - [10/Nov/2016:18:23:54 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"
     6	18.2.237.118 - - [10/Nov/2016:18:23:54 +0530] "GET / HTTP/1.0" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"
     7	78.2.237.118 - - [10/Nov/2016:18:23:59 +0530] "GET / HTTP/1.1" 200 8 "-" "-"
     8	98.1.237.118 - - [10/Nov/2016:18:24:15 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"
     9	128.142.237.118 - - [10/Nov/2016:18:24:16 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"
    10	154.2.237.118 - - [10/Nov/2016:18:24:17 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)" 
  ********************************************************
If this is related to the above First Question we can Pipe the ‘Sed’ to it and get the result.

Question:
=========
3. Modify your application to group together every IP address in the same subnet (example: 139.240.10.0/24) and count the total bandwidth consumed by each subnet.

Solution :
==========

Logic :
====

1) Will find all the Ip address in the log and write it into a file 
2) Will Iterate though each file ( which is IP address ) and then pass if to a function where we will find the subnet ( we have to hardcode the subnet )
3) Write the output of that into a file and use the awk command to find the top 10 bandwidth consumers.


#!/usr/bin/ruby

import ipaddress

ip = awk ‘{print $1}’ 

ip.each do |i|

   p =  ipaddress.ip_address(‘i’) in ipaddress.ip_network(‘ 192.0.0.0/16 ‘)

end

Question:
=========
	1.Modify your application to include activity from the last 3 hours (or 10,000 lines - whichever is smaller)


Soultion:
=======

#!/usr/bin/bash

####Get Entries within the last 3 hours#####

file1 = awk -vDate=`date -d’now-3 hours’ +[%d/%b/%Y:%H:%M:%S` ‘$4 > Date {print Date, $0}’ access.log 

file2 = see -n ‘1, 10000p’ access.log

a = `du -sch file1`
b = `du -sch file2`
  
          if [ $a -gt $b ]
           then
            echo “File1 is larger than FIle2”
            echo $File2
           else
            echo “File1 is smaller than File2”
             echo $File1
           fi

