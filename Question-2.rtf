{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fswiss\fcharset0 ArialMT;\f1\fnil\fcharset0 AndaleMono;}
{\colortbl;\red255\green255\blue255;\red26\green26\blue26;\red255\green255\blue255;\red26\green26\blue26;
\red16\green60\blue192;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid1\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid101\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid201\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}}
\margl1440\margr1440\vieww25400\viewh13440\viewkind0
\deftab720
\pard\tx220\tx720\pardeftab720\li720\fi-720
\ls1\ilvl0
\f0\b\fs28 \cf2 \cb3 Question:\
=========
\b0\fs26 \
1. Write a small program (shellscript, python, perl, ruby are all permissible) to uncover the top 10 bandwidth consumers as logged by a standard nginx/Apache 2.2.x webserver log.\
\
Solution:\
=========\
So the most bandwidth consumers will be the numbers of users who had logged into the server multiple time; so if we can get the top 10 IP address which is recorded in the logs should be the workaround.\
\
Considering the log file if that we are checking is access.log than \
\
======\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural

\f1\fs24 \cf0 \cb1 \CocoaLigature0 #!/usr/local/bin/bash\
\
#### Doing the awk on the file to find the IP address ####\
#### Sort -nr   - to sort the IPadress ####\
#### uniq -c    - will give the counts of unqiue entries \
#### Sort -r    - Sort in the Decending order \
#### head -n10  - Gives the top 10 entries\
\
   awk '\{print $1\}' access.log | sort -nr | uniq -c | sort -r | head -n10\
\pard\tx220\tx720\pardeftab720\li720\fi-720

\f0\fs26 \cf4 \cb1 \CocoaLigature1 ======\
\
Example Output :\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural

\f1\fs24 \cf0 \cb1 \CocoaLigature0      27 68.12.37.118\
     23 68.14.23.63\
     13 10.82.21.20\
     10 \cb1 68.142.27.112\
      8 68.12.27.12\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural

\f0\b\fs28 \cf0 Question :\
===========
\b0\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720
\ls2\ilvl0
\fs26 \cf2 \cb3 \CocoaLigature1 2. Modify your application to only inspect the last 10,000 lines of the log\
\
Solution :\
=======\
I believe the requirement here is to print the 10,000lines in the log which can be done using :\
   \
     *****************\
         see -n \'911,10000p\'92 access.log\
     \cf4 \cb1 *****************\
\
For example :\
    ********************************************************\
\ls2\ilvl0\cf0 \cb1           $ 
\f1\fs24 \CocoaLigature0 sed -n '1, 10p' access_log-20161111 | cat -n\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural
\cf0      1	13.82.217.20 - - [10/Nov/2016:09:55:27 +0530] "GET / HTTP/1.0" 200 8 "-" "Lynx/2.8.6rel.5 libwww-FM/2.14 SSL-MM/1.4.1 OpenSSL/1.0.0-fips"\
     2	10.182.217.20 - - [10/Nov/2016:09:55:38 +0530] "GET / HTTP/1.0" 200 8 "-" "Wget/1.12 (linux-gnu)"\
     3	101.82.217.20 - - [10/Nov/2016:09:57:23 +0530] "GET / HTTP/1.0" 200 8 "-" "Wget/1.12 (linux-gnu)"\
     4	38.14.237.118 - - [10/Nov/2016:18:17:46 +0530] "GET / HTTP/1.0" 200 8 "-" "-"\
     5	58.42.7.118 - - [10/Nov/2016:18:23:54 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"\
     6	18.2.237.118 - - [10/Nov/2016:18:23:54 +0530] "GET / HTTP/1.0" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"\
     7	78.2.237.118 - - [10/Nov/2016:18:23:59 +0530] "GET / HTTP/1.1" 200 8 "-" "-"\
     8	98.1.237.118 - - [10/Nov/2016:18:24:15 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"\
     9	128.142.237.118 - - [10/Nov/2016:18:24:16 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)"\
    10	154.2.237.118 - - [10/Nov/2016:18:24:17 +0530] "GET / HTTP/1.1" 200 8 "-" "Paranoid_Scanner-Yentscan/2.0 (yo/yentscan)" \
  
\f0\fs26 \cf4 \cb1 \CocoaLigature1 ********************************************************\
If this is related to the above First Question we can Pipe the \'91Sed\'92 to it and get the result.\
\

\b\fs28 Question:\
=========\
3.
\b0\fs26 \cf2 \cb3  Modify your application to group together every IP address in the same subnet (example: {\field{\*\fldinst{HYPERLINK "http://139.240.10.0/24"}}{\fldrslt \cf5 \ul \ulc5 139.240.10.0/24}}) and count the total bandwidth consumed by each subnet.\
\
Solution :\
==========\
\
Logic :\
====\
\
1) Will find all the Ip address in the log and write it into a file \
\cf4 \cb1 2) Will Iterate though each file ( which is IP address ) and then pass if to a function where we will find the subnet ( we have to hardcode the subnet )\
3) Write the output of that into a file and use the awk command to find the top 10 bandwidth consumers.\
\
\
#!/usr/bin/ruby\
\
import ipaddress\
\
ip = awk \'91\{print $1\}\'92 \
\
ip.each do |i|\
\
   p =  ipaddress.ip_address(\'91i\'92) in ipaddress.ip_network(\'91 192.0.0.0/16 \'91)\
\
end\
\

\b\fs28 Question:\
=========\
\pard\tx220\tx720\pardeftab720\li720\fi-720
\ls3\ilvl0
\b0\fs26 \cf2 \cb3 	1.Modify your application to include activity from the last 3 hours (or 10,000 lines - whichever is smaller)\
\
\
Soultion:\
=======\
\
#!/usr/bin/bash\
\
####Get Entries within the last 3 hours#####\
\
file1 = awk -vDate=`date -d\'92now-3 hours\'92 +[%d/%b/%Y:%H:%M:%S` \'91$4 > Date \{print Date, $0\}\'92 access.log \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural
\cf4 \cb1 \
file2 = see -n \'911, 10000p\'92 access.log\
\
a = `du -sch file1`\
b = `du -sch file2`\
  \
          if [ $a -gt $b ]\
           then\
            echo \'93File1 is larger than FIle2\'94\
            echo $File2\
           else\
            echo \'93File1 is smaller than File2\'94\
             echo $File1\
           fi\
\
\
}